{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EPA Air Toxics Screen Data Cleaneing ###\n",
    "\n",
    "# function to read and add 'Year' column\n",
    "def read_and_add_year(file_path, year):\n",
    "    df_cancer = pd.read_csv(file_path + f'/{year}_Cancer_Risk_in_a_million_and_Noncancer_Risk_hazard_quotient.csv')\n",
    "    df_cancer.insert(0, 'Year', year)\n",
    "    return df_cancer\n",
    "\n",
    "# Define file path\n",
    "file_path = 'data/epa-airtoxscreen'\n",
    "\n",
    "# Read and add 'Year' column\n",
    "cancer_2014 = read_and_add_year(file_path, 2014)\n",
    "cancer_2017 = read_and_add_year(file_path, 2017)\n",
    "cancer_2018 = read_and_add_year(file_path, 2018)\n",
    "cancer_2019 = read_and_add_year(file_path, 2019)\n",
    "\n",
    "# function to remove rows with total cancer risk less than 0.01\n",
    "def cancer_rows(*cancer_dfs):\n",
    "    return [df[df['Total Cancer Risk (per million)'] >= 1] for df in cancer_dfs]\n",
    "\n",
    "# Remove rows\n",
    "cancer_2014, cancer_2017, cancer_2018, cancer_2019 = cancer_rows(cancer_2014, cancer_2017, cancer_2018, cancer_2019)\n",
    "\n",
    "# Concatenate DataFrames for all years\n",
    "epa_combined = pd.concat([cancer_2014, cancer_2017, cancer_2018, cancer_2019], ignore_index=True)\n",
    "\n",
    "# format columns\n",
    "epa_combined = epa_combined.drop(columns=['EPA Region','FIPS'])\n",
    "epa_combined = epa_combined.rename(columns={'Tract': 'CensusTract'})\n",
    "epa_combined = epa_combined[epa_combined['County'] != 'Entire State']\n",
    "epa_combined = epa_combined.loc[:, epa_combined.sum() != 0]\n",
    "\n",
    "# reorder columns\n",
    "epa_combined = epa_combined[['CensusTract', 'Year', 'State', 'County'] + [col for col in epa_combined.columns if col not in ['CensusTract', 'Year', 'State', 'County']]]\n",
    "\n",
    "# print to csv\n",
    "epa_combined.to_csv('data/epa-airtoxscreen/epa_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by census tract and year, then aggregate the pollutants column\n",
    "grouped = epa_combined.groupby(['CensusTract', 'Year'])['Pollutant Name'].apply(lambda x: ' | '.join(x)).reset_index()\n",
    "\n",
    "# Rename the aggregated column to 'Combined Pollutants'\n",
    "grouped = grouped.rename(columns={'Pollutant Name': 'Combined Pollutants'})\n",
    "\n",
    "# Merge the grouped DataFrame back to the original DataFrame\n",
    "test = pd.merge(epa_combined, grouped, on=['CensusTract', 'Year'], how='left')\n",
    "\n",
    "# drop original pollutants column\n",
    "test = test.drop(columns='Pollutant Name')\n",
    "#reorder columns\n",
    "test = test[['CensusTract', 'Year', 'State', 'County', 'Population', 'Combined Pollutants'] + [col for col in test.columns if col not in ['CensusTract', 'Year', 'State', 'County', 'Population','Combined Pollutants']]]\n",
    "#print to csv\n",
    "test.to_csv('data/epa-airtoxscreen/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Social Vulnerability Index Data Cleaning ###\n",
    "\n",
    "# read data\n",
    "social_2016 = pd.read_csv('data/social-vulnerability-index/Utah-2016.csv')\n",
    "social_2018 = pd.read_csv('data/social-vulnerability-index/Utah-2018.csv')\n",
    "social_2020 = pd.read_csv('data/social-vulnerability-index/Utah-2020.csv')\n",
    "\n",
    "# add 'Year' column\n",
    "social_2016.insert(0, 'Year', 2016)\n",
    "social_2018.insert(0, 'Year', 2018)\n",
    "social_2020.insert(0, 'Year', 2020)\n",
    "\n",
    "# Concatenate DataFrames for all years\n",
    "svi_combined = pd.concat([social_2016, social_2018, social_2020], ignore_index=True)\n",
    "\n",
    "# format columns\n",
    "svi_combined = svi_combined.drop(columns=['ST','STATE','STCNTY',\"LOCATION\"])\n",
    "svi_combined = svi_combined.rename(columns={'FIPS':'CensusTract','COUNTY':'County','ST_ABBR':'State'})\n",
    "\n",
    "# reorder columns\n",
    "svi_combined = svi_combined[['CensusTract', 'Year', 'State', 'County'] + [col for col in svi_combined.columns if col not in ['CensusTract', 'Year', 'State', 'County']]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Food access data cleaning ###\n",
    "\n",
    "# read data\n",
    "food_2010 = pd.read_csv('data/USDA_food_access/food_access_2010.csv')\n",
    "food_2015 = pd.read_csv('data/USDA_food_access/food_access_2015.csv')\n",
    "food_2019 = pd.read_csv('data/USDA_food_access/food_access_2019.csv')\n",
    "\n",
    "# add 'Year' column\n",
    "food_2010.insert(0, 'Year', 2010)\n",
    "food_2015.insert(0, 'Year', 2015)\n",
    "food_2019.insert(0, 'Year', 2019)\n",
    "\n",
    "# Concatenate DataFrames for all years\n",
    "food_combined = pd.concat([food_2010, food_2015, food_2019], ignore_index=True)\n",
    "\n",
    "# reorder columns\n",
    "food_combined = food_combined[['CensusTract', 'Year', 'State', 'County'] + [col for col in food_combined.columns if col not in ['CensusTract', 'Year', 'State', 'County']]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all data\n",
    "merged_data = pd.merge(epa_combined, svi_combined, on=['CensusTract','Year','State','County'], how='outer')\n",
    "merged_data = pd.merge(merged_data, food_combined, on=['CensusTract','Year','State','County'], how='outer')\n",
    "merged_data = merged_data.drop_duplicates()\n",
    "\n",
    "# print to csv\n",
    "merged_data.to_csv('data/merged_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
